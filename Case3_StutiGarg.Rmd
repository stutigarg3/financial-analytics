---
title: "Case3-New"
output: html_document
date: '2022-12-07'
---

#Step 1.1 : Loading the data and inspecting the elements.
```{r}
#Loading the Case3Market.csv dataset and saving it to Market variable
Market <- read.csv("Case3Market.csv", header = FALSE, sep=",")

#Next we perform some basic steps to understand the dataset we just loaded.
#This will return the dimensions of the dataset.
dim(Market)

#This line will return the names of columns in the dataset loaded.
names(Market) # “V1" “V2" ... “V7"

#This will help us view the dataset in its entirety. This step helps us to understand the data better and also to check the if there is any missing values.
View(Market)

#Transforming to date V1 column of market to be in date format.
DATE <- as.Date(as.character(Market$V1),"%Y%m%d")
```

```{r}
#Loading the Case3Port.csv dataset and saving it to Port variable
Port <- read.csv("Case3Port.csv", header = FALSE, sep=",")

#Next we perform some basic steps to understand the dataset we just loaded.
#This will return the dimensions of the dataset.
dim(Port)

#This line will return the names of columns in the dataset loaded.
names(Port) # “V1" “V2" ... “V7"

#This will help us view the dataset in its entirety.
View(Port)
```

```{r}
#Loading the Case3FirmSECID.csv dataset and saving it to FirmSECID variable
FirmSECID <- read.csv("Case3FirmSECID.csv", header = TRUE, sep=",")

#Next we perform some basic steps to understand the dataset we just loaded.
#This will return the dimensions of the dataset.
dim(FirmSECID)

#This line will return the names of columns in the dataset loaded.
names(FirmSECID) # “V1" “V2" ... “V7"

#This will help us view the dataset in its entirety.
View(FirmSECID)
```

#Step1.2: Drop Firms with no observations (Data cleaning)
```{r}
#Calculating the number of columns in Port dataset.
ncol_Port <- ncol(Port)

#Calculating the number of rows in Port dataset.
nrow_Port <- nrow(Port)

#Fetching the market excess returns from Market dataset. Also fetching the risk free rate from the and thereby assigning the risk
Market_EXERT <- Market$V2
Rf <- Market$V3

# Indentifying the companies from the datasets imported
SECID <- FirmSECID$secid
PERMNO <- FirmSECID$permno
TICKER <- as.character(FirmSECID$Ticker)
COMNAM <- FirmSECID$Name

#Calculate the number of Nan for each column in Port data file. Delete firms with no observations in the whole sample period.
num_Nan <- rep(0, ncol_Port)
for(i in 1:ncol_Port){ #run the for loop for each column/firm starting from first firm
  num_Nan[i] <- sum (ifelse(is.nan(Port[, i]), 1, 0))# This will find out if the firm has missing values by using the function is.nan, and it will calculate the sum of all missing values for that firm and lastly will store it in the num_Nan variable.
}

# This line will delete the columns/firms where the calculated number of Null values(num_Nan) is equal to the number of rows we calculated. This means we will not consider firms with no values and hence will delete them.
vec_DELETE <- which(num_Nan == nrow_Port)

# Delete the firms that have no observations in the whole sample period
# Given i is a positive integer and is less than the length of TICKER.
SECID_Clean <- SECID[-c(vec_DELETE)]
PERMNO_Clean <- PERMNO[-c(vec_DELETE)]
TICKER_Clean <- TICKER[-c(vec_DELETE)] # TICKER[-c(i)] can return vector TICKER without  ith element of TICKER
COMNAM_Clean <- COMNAM[-c(vec_DELETE)]

# By assigning the value of NULL to a certain column of a data.frame, we delete the corresponding variable in the data.frame.
Port[, vec_DELETE] <- NULL

#Getting the first and the last date of the sample period. The first date is 4th January 1996 while the last date is 31st December 2015
lg <- length(DATE)
DATE[1]
DATE[lg]

#The number of firms that are kept and dropped
ncol_Port_Clean <- ncol(Port)
num_Dropped <- ncol_Port - ncol_Port_Clean

#Calculating the excess return of the firm by finding the difference between firm and risk free rate
Firm_RET <- Port - Rf
```

#Step2 : Individual stock returns
```{r}
# Step 2.1 : For each firm, summarize the excess returns by computing the time-series mean, standard deviation, skewness, kurtosis, minimum, maximum and annualized sharpe ratio. Put the quantile ( 5, 25, 50, 75, 95) of these statistics in one table. Also include IBM in an additional column.

library(e1071)
# Descriptive statistics
#Calculating the descriptive statistics, such as mean, standard deviation, and Sharpe-ratio. First remove all the missing values and then apply mean, sd, min, max etc functions to calculate the mean standard deviation, minimum and maximum value on firm returns for all firms.
Firm_Mean <- apply(Firm_RET, 2, mean, na.rm=TRUE)
Firm_Std <- apply(Firm_RET, 2, sd, na.rm=TRUE)
Firm_Skew <- apply(Firm_RET, 2, skewness, na.rm=TRUE)
Firm_Kurt <- apply(Firm_RET, 2, kurtosis, na.rm=TRUE)
Firm_Min <- apply(Firm_RET, 2, min, na.rm=TRUE)
Firm_Max <- apply(Firm_RET, 2, max, na.rm=TRUE)
Firm_Sharpe <- Firm_Mean/Firm_Std*sqrt(252)

# Calculate descriptive statistics, such as mean,standard deviation, and Sharpe-ratio for IBM
IBM<-Firm_RET[, which(SECID_Clean==106276)]
IBM_Mean <- mean(IBM, na.rm = TRUE)
IBM_Std <- sd(IBM, na.rm = TRUE)
IBM_Skew <- skewness(IBM, na.rm = TRUE)
IBM_Kurt <- kurtosis(IBM, na.rm = TRUE)
IBM_Min <- min(IBM, na.rm = TRUE)
IBM_Max <- max(IBM, na.rm = TRUE)
IBM_Sharpe <- IBM_Mean/IBM_Std*sqrt(252)

# Calculate Quantile for each descriptive statistics. Mean_Quantile reports the 5%, 25%, 50%, 75% and 95% of the average excess returns among different firms. 
Quantile_Percent <- c(0.05, 0.25, 0.5, 0.75, 0.95)
Mean_Quantile <- quantile(Firm_Mean, Quantile_Percent, na.rm=TRUE)
Std_Quantile <- quantile(Firm_Std, Quantile_Percent, na.rm=TRUE)
Skew_Quantile <- quantile(Firm_Skew, Quantile_Percent, na.rm=TRUE)
Kurt_Quantile <- quantile(Firm_Kurt, Quantile_Percent, na.rm=TRUE)
Min_Quantile <- quantile(Firm_Min, Quantile_Percent, na.rm=TRUE)
Max_Quantile <- quantile(Firm_Max, Quantile_Percent, na.rm=TRUE)
Sharpe_Quantile <- quantile(Firm_Sharpe, Quantile_Percent, na.rm=TRUE)

# Constructing a table to present the results in a tabular format
Table_2_1 <- matrix(data=NA,nrow = 7, ncol = 6)
Table_2_1[1,] <- c(IBM_Mean, Mean_Quantile)
Table_2_1[2,] <- c(IBM_Std,Std_Quantile)
Table_2_1[3,] <- c(IBM_Skew,Skew_Quantile)
Table_2_1[4,] <- c(IBM_Kurt,Kurt_Quantile)
Table_2_1[5,] <- c(IBM_Min,Min_Quantile)
Table_2_1[6,] <- c(IBM_Max,Max_Quantile)
Table_2_1[7,] <- c(IBM_Sharpe,Sharpe_Quantile)
rownames(Table_2_1) <- c("Mean", "Std", "Skew", "Kurt", "Min", "Max", "Sharpe-Ratio")
colnames(Table_2_1) <- c("IBM","Q5","Q25","Q50","Q75","Q95")
as.table(round(Table_2_1,2))
```

#Step 2.2 : Identify firms whose Sharpe ratio is at the min, 50 and max quantile, respectively. Create a table to summarize these Sharpe ratios. In addition, for each of these firms, summarize the sample length, the starting date and the ending date.
```{r}
# Identifying the firms
TICK_vec <- rep(NaN,4)
TICK_vec[1] <- which(SECID_Clean == 106276) # IBM
TICK_vec[2] <- which(Firm_Sharpe == min(Firm_Sharpe, na.rm = TRUE))
TICK_vec[3] <- which((Firm_Sharpe == quantile(Firm_Sharpe, c(0.50), na.rm = TRUE)))
TICK_vec[4] <- which(Firm_Sharpe == max(Firm_Sharpe, na.rm = TRUE))

# Study these firms
Q_Index <- list() # Row numbers that have observable return values
QLength <- integer() # Number of days that have observable return values
QStarting <- character() # Starting date
QEnding <- character() # Ending date

for (i in 1:length(TICK_vec)){
  Q_Index[[i]] <- which(is.nan(Firm_RET[,TICK_vec[i]]) == "FALSE")
  QLength[i] <- length(Q_Index[[i]])
  QStarting[i] <- Market$V1[Q_Index[[i]][1]]
  QEnding[i] <- Market$V1[Q_Index[[i]][QLength[i]]]
}

# Construct table to present previous results
Table_2_2 <- matrix(data=NA,nrow =4, ncol = 4)
Table_2_2[1,] <- round(Firm_Sharpe[TICK_vec],4)
Table_2_2[2,] <- QLength
Table_2_2[3,] <- QStarting
Table_2_2[4,] <- QEnding
rownames(Table_2_2) <- c("Sharpe-Ratio", "Length", "Start", "End")
colnames(Table_2_2) <- c("IBM","Min","Q50","Max")
as.table(Table_2_2)
```

#Step 3 : Beta Estimation
# For beta estimation to run we first have to drop firms. In our sample, we have about 6000 firms and not all of them share the same length. So, for simplicity reason, we only use firms whose sample length is 5025
```{r}
# Step 3.0 : Dropping firms

# Create a variable to store the number of Nan for firm
Firm_num_Nan <- rep(0, ncol(Firm_RET))

# Calculate the number of Nan for each firm
for(i in 1:ncol(Firm_RET)){
  Firm_num_Nan[i] <- sum (ifelse(is.nan(Firm_RET[, i]), 1, 0))
}

# Find firms that have incomplete sample length
Firm_DELETE <- which(Firm_num_Nan>0)

# Drop the firms with incomplete information during the sample period
SECID_DClean <- SECID_Clean[-c(Firm_DELETE)]
PERMNO_DClean <- PERMNO_Clean[-c(Firm_DELETE)]
TICKER_DClean <- TICKER_Clean[-c(Firm_DELETE)]
COMNAM_DClean <- COMNAM_Clean[-c(Firm_DELETE)]
Firm_DRET <- Firm_RET
Firm_DRET[, Firm_DELETE] <- NULL

# Calculate the number of firms after delete firms with incompelete observations during the sample period
Num_Firms <- ncol(Firm_DRET)

# The number of firms that are dropped
Num_Delete <- ncol_Port_Clean-Num_Firms

# The length, beginning date, and ending date
nrow(Firm_DRET)
DATE[1]
DATE[nrow(Firm_DRET)]
```

```{r}
# Step 3.1 : Unique month

# Find the the specific dates for the end of each month in the sample period. tapply() is applying a function max on date by different groups(months). It will group dates in the same month. This step will help us to find the end date of the month.
End_Month <- tapply(as.character(DATE), substr(DATE, 1, 7), max)

# Create a variable to store the index for the end of each month
End_Month_Index <- rep(NA, length(End_Month))

# Find the row number for the end of each month
for( i in 1:length(End_Month)){
  End_Month_Index[i] <- which(DATE==End_Month[i])
}


## 3.2 : OLS regression firm by firm and month by month.Starting with 3rd month i.e march and looking back 60 days.
Num_Month <- length(End_Month_Index)
Win <- 60
Starting_Month_Index <- 3
Beta_Estimation_3_2 <- matrix(NA, nrow = 240, ncol=1111)

# Firm Beta Estimation
for (i in 1:Num_Firms){ #This for loop is looking across firms
  for(j in Starting_Month_Index:Num_Month){ # This for loop is looking across months
    y <- Firm_DRET[(End_Month_Index[j]-Win+1):End_Month_Index[j], i] # Gather all the 60 days observations 
    x <- Market_EXERT[(End_Month_Index[j]-Win+1):End_Month_Index[j]] # x is assigned the market excess returns
    Model <- lm(y~x) # run the models
    Beta_Estimation_3_2[j,i] <- Model$coefficients[2] # Beta is calculated for each firm 
  }
}
```

#Step 4: Portfolio Sorts
```{r}
# Step 4.1 Construct Portfolios at the end of each month
Month_RET_4 <- matrix(NA, nrow =Num_Month, ncol =ncol(Firm_DRET))
for (j in Starting_Month_Index:(Num_Month-1)){
  for (i in 1:Num_Firms){
    Month_RET_4[j,i]<-sum(Firm_DRET[(End_Month_Index[j]+1):End_Month_Index[(j+1)], i],
    na.rm=TRUE)
  }

  # Use beta quantiles as cutoff points.In order to put different firms into different portfolios, we use quantiles
  cutoff <- quantile(Beta_Estimation_3_2[j,], c(0, 0.2, 0.4, 0.6,0.8,1), na.rm=TRUE)
  # form portfolios at the end of each month
  Port_RET_Q[j,1] <- mean(Month_RET_4[j, which((Beta_Estimation_3_2[j,] >= cutoff[1])
  & (Beta_Estimation_3_2[j,] <= cutoff[2]))])
  Port_RET_Q[j,2] <- mean(Month_RET_4[j, which((Beta_Estimation_3_2[j,] > cutoff[2])
  & (Beta_Estimation_3_2[j,] <= cutoff[3]))])
  Port_RET_Q[j,3] <- mean(Month_RET_4[j, which((Beta_Estimation_3_2[j,] > cutoff[3])
  & (Beta_Estimation_3_2[j,] <= cutoff[4]))])
  Port_RET_Q[j,4] <- mean(Month_RET_4[j, which((Beta_Estimation_3_2[j,] > cutoff[4])
  & (Beta_Estimation_3_2[j,] <= cutoff[5]))])
  Port_RET_Q[j,5] <- mean(Month_RET_4[j, which((Beta_Estimation_3_2[j,] > cutoff[5])
  & (Beta_Estimation_3_2[j,] <= cutoff[6]))])
}

# Step 4.2 Portfolio Returns
# Calculate the time series average for each portfolio in each quantile
Port_RET_QMean <- apply(Port_RET_Q,2,mean, na.rm = TRUE)
Port_RET_Qsd <- apply(Port_RET_Q,2,sd, na.rm = TRUE)
Port_RET_QSharpe <- Port_RET_QMean/Port_RET_Qsd*sqrt(12)

# Create a barplot for these five time-series averages and Sharpe Ratio
jpeg(filename = "Case3_Portfolio_4_2.jpeg")
barplot(Port_RET_QMean, xlab="Quantile",space= 1.5,ylab=c("Average Returns"))
dev.off()

## compute the p-value for time-series mean
x_4 <- rep(1,Num_Month)
lmSUM <- summary(lm(Port_RET_Q~0+x_4))
Port_RET_Q_pvalue <- rep(NA,6)
Port_RET_Q_pvalue[1] <- lmSUM[["Response Y1"]]$coefficients[1,4]
Port_RET_Q_pvalue[2] <- lmSUM[["Response Y2"]]$coefficients[1,4]
Port_RET_Q_pvalue[3] <- lmSUM[["Response Y3"]]$coefficients[1,4]
Port_RET_Q_pvalue[4] <- lmSUM[["Response Y4"]]$coefficients[1,4]
Port_RET_Q_pvalue[5] <- lmSUM[["Response Y5"]]$coefficients[1,4]
Port_RET_Q_pvalue[6] <- lmSUM[["Response Y6"]]$coefficients[1,4]

## Table output
Table_4_2 <- matrix(data=NA,nrow =4, ncol = 6)
Table_4_2[1,] <- Port_RET_QMean
Table_4_2[2,] <- Port_RET_Qsd
Table_4_2[3,] <- Port_RET_Q_pvalue
Table_4_2[4,] <- Port_RET_QSharpe
rownames(Table_4_2) <- c("Mean","Std","p-value","Sharpe-Ratio")
colnames(Table_4_2) <- c("Q1","Q2","Q3","Q4","Q5","Q5-Q1")
as.table(round(Table_4_2,3))

# step1: set up null and alternative

# step2: compute t-statistics
Test_Value_4_3 <- lmSUM[["Response Y6"]]$coefficients[1,3]

# step3:
decisionRule <- Test_Value_4_3>qt(0.95,(Num_Month-Starting_Month_Index-1))

# Step4:
Test_Result_4_3 <- ifelse(decisionRule, "Reject", "Can’t reject")
```

